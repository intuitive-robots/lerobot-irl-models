# Beso policy configuration with language instruction support
# @package _global_.policy

_target_: src.policies.beso.modelling_beso.BesoPolicy

# Input/Output dimensions
n_obs_steps: 2
chunk_size: 32
n_action_steps: 32

# State/action dimensions - adjust based on your robot setup
input_shapes:
  observation.state: [7]  # joint positions
  observation.images.right_cam_image: [3, 126, 224]
  observation.images.wrist_cam_image: [3, 126, 224]

output_shapes:
  action: [8]  # 7 joints + 1 gripper

# Network architecture
hidden_dim: 512
n_heads: 8
depth: 6

# Diffusion parameters
num_inference_steps: 10
sigma_min: 0.002
sigma_max: 80
rho: 7

# Language instruction parameters
use_language: true
clip_model_name: "openai/clip-vit-base-patch32"  # or "openai/clip-vit-large-patch14"
freeze_clip: true  # Set to false if you want to finetune CLIP
language_feature: "task"  # The key in the batch containing language instructions

# Feature configuration
input_features:
  - observation.state
  - observation.images.right_cam_image
  - observation.images.wrist_cam_image
  - task  # Language instruction

output_features:
  - action

# Normalization
normalization_mapping:
  observation.state: observation.state
  action: action
